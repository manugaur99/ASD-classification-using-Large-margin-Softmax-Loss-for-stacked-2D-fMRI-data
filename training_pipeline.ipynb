{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manugaur99/ASD-classification-using-Large-margin-Softmax-Loss-for-stacked-2D-fMRI-data/blob/main/training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXLyYnMlzwm1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aYY12sbztBo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "%matplotlib inline\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pathlib\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from random import SystemRandom\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "#from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3y8n0TezvVF"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"We're using =>\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaxE8I_yjhbn"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  use_cuda = True\n",
        "else:\n",
        "  use_cuda = False\n",
        "print(use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbJmpVVltnK4"
      },
      "outputs": [],
      "source": [
        "df_labels = pd.read_csv('/content/drive/MyDrive/ABIDE_NYU/phenotypes/Phenotypic_V1_0b_preprocessed1.csv')#path \n",
        "\n",
        "#df_labels = pd.read_csv('/content/drive/MyDrive/func_mean/Phenotypic_V1_0b_preprocessed1.csv')  ------ for jassi's drive \n",
        "\n",
        "\n",
        "#df_labels = df_labels[(df_labels['FILE_ID'].str[0:3].isin([\"NYU\"]))]\n",
        "df_labels = df_labels[(df_labels['FILE_ID'].str[0:3].isin([\"NYU\"])) | (df_labels['FILE_ID'].str[0:3].isin([\"USM\"])) | (df_labels['FILE_ID'].str[0:6].isin([\"UCLA_1\"])) | (df_labels['FILE_ID'].str[0:4].isin([\"UM_1\"]))] # only NYU data\n",
        "df_labels.DX_GROUP = df_labels.DX_GROUP.map({1: 1, 2:0})      # 1: has autism  0: doesn't have autism\n",
        "print(len(df_labels))\n",
        "\n",
        "labels = {}\n",
        "for row in df_labels.iterrows():\n",
        "    file_id = row[1]['FILE_ID']\n",
        "    y_label = row[1]['DX_GROUP']\n",
        "    if file_id == 'no_filename':\n",
        "        continue\n",
        "    assert(file_id not in labels)\n",
        "    labels[file_id] = y_label\n",
        "\n",
        "torch.save(labels, 'labels.pt')\n",
        "print(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7ya9pRdtoWV"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.ToPILImage(),\n",
        "  transforms.Resize((64,64)),\n",
        "  transforms.RandomHorizontalFlip(p=0.30),\n",
        "  transforms.RandomVerticalFlip(0.30),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.4103,0.4103,0.4103],[0.3906,0.3906,0.3906])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "  transforms.ToPILImage(),\n",
        "  transforms.Resize((64,64)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.4105,0.4105,0.4105], [0.3904,0.3904,0.3904])\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYchpHEM0uLr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcmB1YtTtp96"
      },
      "outputs": [],
      "source": [
        "class AbideDataset(Dataset):\n",
        "    def __init__(self, image_dir, labels, split):\n",
        "        self.image_dir = image_dir       #Dataset/\n",
        "        self.images = os.listdir(image_dir)\n",
        "        self.labels = labels\n",
        "        self.split = split \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "    #   mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".jpg\", \"_mask.gif\"))\n",
        "        image = np.load(img_path)           #73x61X3\n",
        "\n",
        "\n",
        "        filename = self.images[index]\n",
        "        #print(image.mean())\n",
        "        #print(\"image is \" , self.images[index] , \"length is \", length)\n",
        "        var = filename[:3]\n",
        "        if var== \"NYU\" or var==\"USM\":\n",
        "          key = filename[:11]\n",
        "        elif var ==\"UCL\":\n",
        "          key = filename[:14]\n",
        "        else:\n",
        "          key = filename[:12]\n",
        " \n",
        "\n",
        "        label = self.labels[key]\n",
        "        if self.split== 'train':\n",
        "          image = train_transform(image)\n",
        "        else:\n",
        "          image = test_transform(image)\n",
        "          \n",
        "\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkqUWKHC0aPn"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/func_mean/train/'\n",
        "val_dir = '/content/drive/MyDrive/func_mean/val/'\n",
        "test_dir = '/content/drive/MyDrive/func_mean/test/'\n",
        "\n",
        "\n",
        "train_ds =  AbideDataset(image_dir= train_dir,labels =labels, split = 'train')\n",
        "test_ds =  AbideDataset(image_dir= test_dir,labels =labels, split = 'test')\n",
        "val_ds =  AbideDataset(image_dir= val_dir,labels =labels, split= 'val')\n",
        "\n",
        "\n",
        "train_loader = DataLoader(  \n",
        "        train_ds,\n",
        "        batch_size=32,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        shuffle=True,\n",
        "    )\n",
        "val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=32,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=32,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk86jfKT2F3S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izRaCdtJttg-"
      },
      "outputs": [],
      "source": [
        "train_count = train_ds.__len__()\n",
        "val_count = val_ds.__len__()\n",
        "test_count = test_ds.__len__()\n",
        "print(train_count)\n",
        "print(val_count)\n",
        "print(test_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvHHpbJZys-9"
      },
      "source": [
        "#CBAM module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxvcYMT10Hkt"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn   \n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "\n",
        "    def __init__(self, n_channels_in, reduction_ratio, kernel_size):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.n_channels_in = n_channels_in\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.channel_attention = ChannelAttention(n_channels_in, reduction_ratio)\n",
        "        self.spatial_attention = SpatialAttention(kernel_size)\n",
        "\n",
        "    def forward(self, f):\n",
        "        #print(\"input to CBAM:     \", f.shape)\n",
        "        chan_att = self.channel_attention(f)\n",
        "        #print(\"Chann attn map:    \",chan_att.shape, f.shape)\n",
        "        fp = chan_att * f\n",
        "        #print(\"chann attn output: \",fp.shape)\n",
        "        spat_att = self.spatial_attention(fp)\n",
        "        #print(\"spatial attn map:  \",spat_att.shape)\n",
        "        fpp = spat_att * fp\n",
        "        #print(\"output by CBAM:    \", fpp.shape)\n",
        "        return fpp\n",
        "\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        assert kernel_size % 2 == 1, \"Odd kernel size required\"\n",
        "        self.conv = nn.Conv2d(in_channels = 2, out_channels = 1, kernel_size = kernel_size, padding= int((kernel_size-1)/2))\n",
        "        # batchnorm\n",
        "\n",
        "    def forward(self, x):\n",
        "        max_pool = self.agg_channel(x, \"max\")\n",
        "        avg_pool = self.agg_channel(x, \"avg\")\n",
        "        pool = torch.cat([max_pool, avg_pool], dim = 1)\n",
        "        conv = self.conv(pool)\n",
        "        # batchnorm ????????????????????????????????????????????\n",
        "        conv = conv.repeat(1,x.size()[1],1,1)\n",
        "        att = torch.sigmoid(conv)        \n",
        "        return att\n",
        "\n",
        "    def agg_channel(self, x, pool = \"max\"):\n",
        "        b,c,h,w = x.size()\n",
        "        x = x.view(b, c, h*w)\n",
        "        x = x.permute(0,2,1)\n",
        "        if pool == \"max\":\n",
        "            x = F.max_pool1d(x,c)\n",
        "        elif pool == \"avg\":\n",
        "            x = F.avg_pool1d(x,c)\n",
        "        x = x.permute(0,2,1)\n",
        "        x = x.view(b,1,h,w)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, n_channels_in, reduction_ratio):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.n_channels_in = n_channels_in\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.middle_layer_size = int(self.n_channels_in/ float(self.reduction_ratio))\n",
        "\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Linear(self.n_channels_in, self.middle_layer_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.middle_layer_size, self.n_channels_in)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        kernel = (x.size()[2], x.size()[3])\n",
        "        avg_pool = F.avg_pool2d(x, kernel )\n",
        "        max_pool = F.max_pool2d(x, kernel)\n",
        "\n",
        "        \n",
        "        avg_pool = avg_pool.view(avg_pool.size()[0], -1)\n",
        "        max_pool = max_pool.view(max_pool.size()[0], -1)\n",
        "        \n",
        "\n",
        "        avg_pool_bck = self.bottleneck(avg_pool)\n",
        "        max_pool_bck = self.bottleneck(max_pool)\n",
        "\n",
        "        pool_sum = avg_pool_bck + max_pool_bck\n",
        "\n",
        "        sig_pool = torch.sigmoid(pool_sum)\n",
        "        sig_pool = sig_pool.unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "        out = sig_pool.repeat(1,1,kernel[0], kernel[1])\n",
        "        return out\n",
        "\n",
        "def main():\n",
        "    # ca = CBAM() \n",
        "\n",
        "\n",
        "    f = torch.FloatTensor([\n",
        "        [\n",
        "            [[1,1,1,1,1], [1,1,2,1,1], [1,1,1,1,1]],\n",
        "            [[2,2,2,2,2], [2,2,3,2,2], [2,2,2,2,2]],\n",
        "            [[3,3,3,3,3], [3,3,4,3,3], [3,3,3,3,3]]\n",
        "        ]\n",
        "    ])\n",
        "\n",
        "    #print(f.size())\n",
        "\n",
        "    # sa = SpatialAttention(kernel_size = 3)\n",
        "    # sa(f)\n",
        "    cbam = CBAM(n_channels_in = f.size()[1],reduction_ratio = 2, kernel_size = 3) \n",
        "\n",
        "\n",
        "    fpp = cbam(f)\n",
        "    print(fpp.size())\n",
        "    print(fpp)\n",
        "    # print(f)\n",
        "    # print(fp)\n",
        "    \n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.FloatTensor(2048,2)\n",
        "x.shape\n",
        "y = nn.Parameter(x)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "fGq2N0idSfdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#L-Softmax"
      ],
      "metadata": {
        "id": "JtnteNwPwq2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from scipy.special import binom\n",
        "\n",
        "\n",
        "class LSoftmaxLinear(nn.Module):\n",
        "\n",
        "    def __init__(self, input_features, output_features, margin, device):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_features  # number of input feature i.e. output of the last fc layer\n",
        "        self.output_dim = output_features  # number of output = class numbers\n",
        "        self.margin = margin  # m\n",
        "        self.beta = 100\n",
        "        self.beta_min = 0\n",
        "        self.scale = 0.99\n",
        "\n",
        "        self.device = device  # gpu or cpu\n",
        "\n",
        "        # Initialize L-Softmax parameters\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(input_features, output_features))\n",
        "        self.divisor = math.pi / self.margin  # pi/m\n",
        "        self.C_m_2n = torch.Tensor(binom(margin, range(0, margin + 1, 2))).to(device)  # C_m{2n}\n",
        "        self.cos_powers = torch.Tensor(range(self.margin, -1, -2)).to(device)  # m - 2n\n",
        "        self.sin2_powers = torch.Tensor(range(len(self.cos_powers))).to(device)  # n\n",
        "        self.signs = torch.ones(margin // 2 + 1).to(device)  # 1, -1, 1, -1, ...\n",
        "        self.signs[1::2] = -1\n",
        "\n",
        "    def calculate_cos_m_theta(self, cos_theta):\n",
        "        sin2_theta = 1 - cos_theta**2\n",
        "        cos_terms = cos_theta.unsqueeze(1) ** self.cos_powers.unsqueeze(0)  # cos^{m - 2n}\n",
        "        sin2_terms = (sin2_theta.unsqueeze(1)  # sin2^{n}\n",
        "                      ** self.sin2_powers.unsqueeze(0))\n",
        "\n",
        "        cos_m_theta = (self.signs.unsqueeze(0) *  # -1^{n} * C_m{2n} * cos^{m - 2n} * sin2^{n}\n",
        "                       self.C_m_2n.unsqueeze(0) *\n",
        "                       cos_terms *\n",
        "                       sin2_terms).sum(1)  # summation of all terms\n",
        "\n",
        "        return cos_m_theta\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_normal_(self.weight.data.t())\n",
        "\n",
        "    def find_k(self, cos):\n",
        "        # to account for acos numerical errors\n",
        "        eps = 1e-7\n",
        "        cos = torch.clamp(cos, -1 + eps, 1 - eps)\n",
        "        acos = cos.acos()\n",
        "        k = (acos / self.divisor).floor().detach()\n",
        "        return k\n",
        "\n",
        "    def forward(self, input, target=None):\n",
        "        if self.training:\n",
        "            assert target is not None\n",
        "            x, w = input, self.weight\n",
        "            #print(\"input shape :\",x.shape)\n",
        "            #print(\"weight shape:\", w.shape)\n",
        "            beta = max(self.beta, self.beta_min)\n",
        "            logit = x.mm(w)\n",
        "            #print(\"matrix multiplication to get logit : \", logit.shape)\n",
        "            indexes = range(logit.size(0))\n",
        "            #print(\"indexes: \", indexes.shape)\n",
        "            logit_target = logit[indexes, target]\n",
        "            #print(\"logit_taget shape: \",logit_target.shape)\n",
        "\n",
        "            # cos(theta) = w * x / ||w||*||x||\n",
        "            w_target_norm = w[:, target].norm(p=2, dim=0)\n",
        "            x_norm = x.norm(p=2, dim=1)\n",
        "            cos_theta_target = logit_target / (w_target_norm * x_norm + 1e-10)\n",
        "\n",
        "            # equation 7\n",
        "            cos_m_theta_target = self.calculate_cos_m_theta(cos_theta_target)\n",
        "\n",
        "            # find k in equation 6\n",
        "            k = self.find_k(cos_theta_target)\n",
        "\n",
        "            # f_y_i\n",
        "            logit_target_updated = (w_target_norm *\n",
        "                                    x_norm *\n",
        "                                    (((-1) ** k * cos_m_theta_target) - 2 * k))\n",
        "            logit_target_updated_beta = (logit_target_updated + beta * logit[indexes, target]) / (1 + beta)\n",
        "\n",
        "            logit[indexes, target] = logit_target_updated_beta\n",
        "            self.beta *= self.scale\n",
        "            return logit\n",
        "        else:\n",
        "            #assert target is None\n",
        "            return input.mm(self.weight)"
      ],
      "metadata": {
        "id": "FHgwmzB_No8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modifying model for 64,64 images"
      ],
      "metadata": {
        "id": "7gb8OsUBJ0sT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkudHE6c0CIY"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "# taken from https://github.com/kuangliu/pytorch-cifar\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "# class BasicBlock(nn.Module):\n",
        "#     expansion = 1\n",
        "\n",
        "#     def __init__(self, in_planes, planes, stride=1, reduction_ratio = 1, kernel_cbam = 3, use_cbam = False):\n",
        "#         super(BasicBlock, self).__init__()\n",
        "#         self.use_cbam = use_cbam\n",
        "#         self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(planes)\n",
        "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "#         if self.use_cbam:\n",
        "#             self.cbam = CBAM(n_channels_in = self.expansion*planes, reduction_ratio = reduction_ratio, kernel_size = kernel_cbam)\n",
        "\n",
        "\n",
        "#         self.shortcut = nn.Sequential()\n",
        "#         if stride != 1 or in_planes != self.expansion*planes:\n",
        "#             self.shortcut = nn.Sequential(\n",
        "#                 nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(self.expansion*planes)\n",
        "#             )\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = F.relu(self.bn1(self.conv1(x)))\n",
        "#         out = self.bn2(self.conv2(out))\n",
        "\n",
        "#         #cbam\n",
        "#         if self.use_cbam:\n",
        "#             out = self.cbam(out)\n",
        "\n",
        "#         out += self.shortcut(x)\n",
        "#         out = F.relu(out)\n",
        "#         return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, reduction_ratio = 16, kernel_cbam = 3, use_cbam = False):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.use_cbam = use_cbam\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "        if self.use_cbam:\n",
        "            self.cbam = CBAM(n_channels_in = self.expansion*planes, reduction_ratio = reduction_ratio, kernel_size = kernel_cbam)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "\n",
        "        #cbam\n",
        "        if self.use_cbam:\n",
        "            out = self.cbam(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=2, reduction_ratio = 16, kernel_cbam = 3, use_cbam_block= False, use_cbam_class = False):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.kernel_cbam = kernel_cbam\n",
        "        self.use_cbam_block = use_cbam_block\n",
        "        self.use_cbam_class = use_cbam_class\n",
        "\n",
        "        #print(use_cbam_block, use_cbam_class)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "#--------------------------------------------------------------------------------------       \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "       # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "        self.lsoftmax_linear = LSoftmaxLinear(input_features=2048, output_features=2, margin=3, device= device)\n",
        "       # self.softmax = nn.Softmax(dim = 1)\n",
        "#------------------------------------------------------------------------------------------\n",
        "        if self.use_cbam_class:\n",
        "            self.cbam = CBAM(n_channels_in = 512*block.expansion, reduction_ratio = reduction_ratio, kernel_size = kernel_cbam)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, self.reduction_ratio, self.kernel_cbam, self.use_cbam_block))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        #print(\"input shape:             \",x.shape)\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        #print(\"Conv1 output:            \",out.shape)\n",
        "        out = self.maxpool(out)\n",
        "        #print(\"maxpool output:          \",out.shape)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "        #print(\"----------LAYER 1 output:\",out.shape)\n",
        "        out = self.layer2(out)\n",
        "        #print(\"----------LAYER 2 output:\",out.shape)\n",
        "        out = self.layer3(out)\n",
        "        #print(\"----------LAYER 3 output:\",out.shape)\n",
        "        out = self.layer4(out)\n",
        "        #print(\"----------LAYER 4 output:\",out.shape)\n",
        "\n",
        "        if self.use_cbam_class:\n",
        "            out = out  + self.cbam(out)\n",
        "            #print(\"CBAM output:         \",out.shape)\n",
        "        out = self.avgpool(out)\n",
        "        #print(\"AVGpool output:          \",out.shape)\n",
        "        out = torch.flatten(out, 1)\n",
        "        #print(\"flattened shape:         \",out.shape)\n",
        "        #out = self.fc(out)\n",
        "        #print(\"final linear layer:      \",out)\n",
        "        out = self.lsoftmax_linear(input=out, target=labels)\n",
        "        #out = self.softmax(out)\n",
        "        #print(\"after softmax:           \",out)\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------\n",
        "        #out = F.avg_pool2d(out, 4)\n",
        "        #out = out.view(out.size(0), -1)\n",
        "        #print(\"view changed;            \",out.shape)\n",
        "      \n",
        "        #out = self.linear(out)\n",
        "        #print(\"final linear layer:      \",out.shape)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def ResNet18(reduction_ratio = 1, kernel_cbam = 3, use_cbam_block = False, use_cbam_class = False):\n",
        "#     print(kernel_cbam)\n",
        "#     return ResNet(\n",
        "#                 BasicBlock, \n",
        "#                 [2,2,2,2], \n",
        "#                 reduction_ratio= reduction_ratio,\n",
        "#                 kernel_cbam = kernel_cbam,\n",
        "#                 use_cbam_block= use_cbam_block,\n",
        "#                 use_cbam_class = use_cbam_class\n",
        "#                 )\n",
        "\n",
        "# def ResNet34(reduction_ratio = 1, kernel_cbam = 3, use_cbam_block = False, use_cbam_class = False):\n",
        "#     return ResNet(\n",
        "#         BasicBlock,\n",
        "#         [3,4,6,3],\n",
        "#         reduction_ratio= reduction_ratio, \n",
        "#         kernel_cbam = kernel_cbam, \n",
        "#         use_cbam_block= use_cbam_block,\n",
        "#         use_cbam_class = use_cbam_class\n",
        "#         )\n",
        "\n",
        "def ResNet50(reduction_ratio = 16, kernel_cbam = 3, use_cbam_block = True, use_cbam_class = True):\n",
        "    return ResNet(\n",
        "        Bottleneck, \n",
        "        [3,4,6,3], \n",
        "        reduction_ratio= reduction_ratio, \n",
        "        kernel_cbam = kernel_cbam, \n",
        "        use_cbam_block= use_cbam_block,\n",
        "        use_cbam_class = use_cbam_class\n",
        "        )\n",
        "\n",
        "def ResNet101(reduction_ratio = 16, kernel_cbam = 3, use_cbam_block = True, use_cbam_class = True):\n",
        "    return ResNet(\n",
        "        Bottleneck, \n",
        "        [3,4,23,3], \n",
        "        reduction_ratio= reduction_ratio, \n",
        "        kernel_cbam = kernel_cbam, \n",
        "        use_cbam_block= use_cbam_block,\n",
        "        use_cbam_class = use_cbam_class\n",
        "        )\n",
        "\n",
        "def ResNet152(reduction_ratio = 1, kernel_cbam = 3, use_cbam_block = False, use_cbam_class = False):\n",
        "    return ResNet(\n",
        "        Bottleneck, \n",
        "        [3,8,36,3], \n",
        "        reduction_ratio= reduction_ratio, \n",
        "        kernel_cbam = kernel_cbam, \n",
        "        use_cbam_block= use_cbam_block,\n",
        "        use_cbam_class = use_cbam_class\n",
        "        )\n",
        "\n",
        "def ResNetk(k, reduction_ratio = 1, kernel_cbam = 3, use_cbam_block = True, use_cbam_class = True ):\n",
        "    possible_depth = [18,34,50,101,152]\n",
        "    assert k in possible_depth, \"Choose a depth in {}\".format(possible_depth)\n",
        "\n",
        "#    if k == 18:\n",
        "#        return ResNet18(reduction_ratio= reduction_ratio, kernel_cbam = kernel_cbam, use_cbam_block= use_cbam_block, use_cbam_class = use_cbam_class)\n",
        "#    elif k == 34:\n",
        "#        return ResNet34(reduction_ratio= reduction_ratio, kernel_cbam = kernel_cbam, use_cbam_block= use_cbam_block, use_cbam_class = use_cbam_class)\n",
        "    if k == 50:\n",
        "        return ResNet50(reduction_ratio= reduction_ratio, kernel_cbam = kernel_cbam, use_cbam_block= use_cbam_block, use_cbam_class = use_cbam_class)\n",
        "    elif k == 101:\n",
        "        return ResNet101(reduction_ratio= reduction_ratio, kernel_cbam = kernel_cbam, use_cbam_block= use_cbam_block, use_cbam_class = use_cbam_class)\n",
        "    elif k == 152:\n",
        "        return ResNet152(reduction_ratio= reduction_ratio, kernel_cbam = kernel_cbam, use_cbam_block= use_cbam_block, use_cbam_class = use_cbam_class)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URdPtzgN1ppY"
      },
      "outputs": [],
      "source": [
        "# !pip install modelsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRaa62o7khVN"
      },
      "outputs": [],
      "source": [
        "model = ResNet50()\n",
        "tensor = torch.rand(1,3,64,64)\n",
        "#model(tensor)\n",
        "model = model.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGHSwm83oBcm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from modelsummary import summary\n",
        "\n",
        "# net = ResNet50()\n",
        "\n",
        "\n",
        "# summary(net, torch.zeros((1, 3, 64, 64)), show_input=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g85_f8yQxhj1"
      },
      "source": [
        "# Hinton's margin loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNMKgKOVxhQ3"
      },
      "outputs": [],
      "source": [
        "def margin_loss(x, labels):\n",
        "    #m = nn.Softmax(dim=1)\n",
        "    batch_size = x.size(0)\n",
        "    #print(\"batch size\", batch_size) \n",
        "    #x = m(x)\n",
        "    v_c = torch.sqrt((x ** 2).sum(dim=1, keepdim=True))\n",
        "    #print(\"v_c shape\", v_c.shape)\n",
        "\n",
        "    left = F.relu(0.9 - v_c).view(batch_size, -1)\n",
        "    right = F.relu(v_c - 0.1).view(batch_size, -1)\n",
        "    #print(\"left shape\", left.shape)\n",
        "    #print(\"right shape\", right.shape)\n",
        "    loss = labels * left + 0.5 * (1.0 - labels) * right\n",
        "    loss = loss.sum(dim=1).mean()\n",
        "    \n",
        "    #print(\"margin loss\",loss)\n",
        "    #print(\"loss shape = \",loss.shape)\n",
        "\n",
        "\n",
        "    return  loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CThHdwV-uTp_"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "#loss_function = torch.nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr= 0.01, momentum=0.9)\n",
        "#optimizer=Adam(model.parameters(),lr=0.01,weight_decay=0.001)\n",
        "\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=25, verbose = True)\n",
        "num_epochs = 150\n",
        "alpha = 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAHFx4wij0Wu"
      },
      "source": [
        "#Mix up Training\n",
        "\n",
        "model(images) >> model(images, labels) for L-softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON1mwtLaj0Jl"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    if use_cuda:\n",
        "        index = torch.randperm(batch_size).cuda()\n",
        "    else:\n",
        "        index = torch.randperm(batch_size)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDgldCCPj-vT"
      },
      "outputs": [],
      "source": [
        "best_accuracy=0.0\n",
        "num_epochs = 300\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    correct = 0\n",
        "    total =  0 \n",
        "    metric = 0 \n",
        "    \n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "      if torch.cuda.is_available():\n",
        "        images= images.cuda().float()\n",
        "        labels=labels.cuda()\n",
        "      images, labels_a, labels_b, lam = mixup_data(images, labels,\n",
        "                                                       alpha, use_cuda)\n",
        "      images, labels_a, labelss_b = map(Variable, (images,\n",
        "                                                      labels_a, labels_b))            \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      \n",
        "      outputs=model(images,labels)\n",
        "      loss = mixup_criterion(loss_function, outputs, labels_a, labels_b, lam)\n",
        "      train_loss+= loss.cpu().data*images.size(0)\n",
        "      _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "\n",
        "      correct += (lam * prediction.eq(labels_a.data).cpu().sum().float()\n",
        "                    + (1 - lam) * prediction.eq(labels_b.data).cpu().sum().float())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "        \n",
        "        \n",
        "      \n",
        "        \n",
        "      #train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "# mix up train accuracy\n",
        "    train_accuracy = 100.*correct/total       \n",
        "    #train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    \n",
        "    \n",
        "     # Evaluation on validation dataset\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      val_accuracy = 0.0\n",
        "      for i, (images,labels) in enumerate(val_loader):\n",
        "        if torch.cuda.is_available():\n",
        "          images=Variable(images.cuda()).float()\n",
        "          labels=Variable(labels.cuda())\n",
        "           #L-softmax   \n",
        "        outputs=model(images,None)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        val_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "      \n",
        "      val_accuracy=val_accuracy/val_count\n",
        "      \n",
        "      #scheduler.step(metric)\n",
        "\n",
        "      print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' val Accuracy: '+str(val_accuracy))\n",
        "      #print('lr:', scheduler.get_last_lr())\n",
        "      \n",
        "      # #Save the best model\n",
        "      \n",
        "      if val_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IAsNf-Z-juK"
      },
      "outputs": [],
      "source": [
        "print(best_accuracy) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "model.load_state_dict(torch.load('best_checkpoint.model'))\n",
        "model2 =copy.deepcopy(model)"
      ],
      "metadata": {
        "id": "6XUbt94UI_1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XBRbNF7avdZ"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('best_checkpoint.model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgssRRm9sP5U"
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    test_accuracy = 0.0\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "      if torch.cuda.is_available():\n",
        "        images=Variable(images.cuda()).float()\n",
        "        labels=Variable(labels.cuda())\n",
        "            \n",
        "      outputs=model(images,None)\n",
        "      _,prediction=torch.max(outputs.data,1)\n",
        "      test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "    \n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    \n",
        "    #scheduler.step(metric)\n",
        "\n",
        "    print(' Test Loss: '+str(test_loss)+' Test Accuracy: '+str(test_accuracy))\n",
        "    #print('lr:', scheduler.get_last_lr())\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HfwklyRg38zl",
        "dZ5fzxWqSevQ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}